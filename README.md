## üß† Fine-Tuning a Domain-Specific LLM that Outperformed GPT-4o & Gemini

This project demonstrates how a carefully fine-tuned domain-specific Language Model was able to outperform state-of-the-art models like **GPT-4o** and **Gemini** on a targeted task involving **missing key point identification** from text-based answers.

---

### üìå Project Highlights
- üöÄ Fine-tuned using the **LoRA technique** on a domain-specific dataset.
- üìä Outperformed GPT-4o and Gemini on precision, recall, and F1-score.
- üìÅ Includes **dataset creation**, **training**, and **evaluation** pipeline.
- üîç Focused on identifying **missing key points** from generated answers.

---

## üóÇÔ∏è Project Structure
```bash
.
‚îú‚îÄ‚îÄ Dataset/
‚îÇ   ‚îú‚îÄ‚îÄ your_dataset.csv              # Original dataset with paragraphs
‚îÇ   ‚îú‚îÄ‚îÄ output.json                   # Generated QA pairs with missing key points
‚îÇ   ‚îú‚îÄ‚îÄ formatted_train_data.json     # Alpaca-style training data
‚îú‚îÄ‚îÄ Training/
‚îÇ   ‚îú‚îÄ‚îÄ finetune.ipynb                # Fine-tuning using Unsloth & LoRA
‚îú‚îÄ‚îÄ Evaluation/
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.ipynb                # Custom evaluation pipeline
‚îú‚îÄ‚îÄ Results/
‚îÇ   ‚îú‚îÄ‚îÄ *.png                         # Performance visualization images
```

---

## üßæ Dataset Creation

We used **OpenAI GPT-4o via Azure** to synthetically generate QA pairs from long paragraphs:
- Extracted 2‚Äì5 key points from a paragraph.
- Randomly removed 1‚Äì4 key points to simulate incomplete answers.
- Generated JSON in the format:

```json
{
  "Answer": "paragraph with missing key points",
  "key_points": ["point1", "point2", ...],
  "PointsMissed": ["missing_point1", "missing_point2"]
}
```

---

## ‚öôÔ∏è Fine-Tuning Pipeline

- Used **[Unsloth](https://github.com/unslothai/unsloth)** for efficient LoRA fine-tuning.
- Trained on **formatted Alpaca-style prompts** with 300+ examples.
- Model used: `Meta-Llama-3.1-8B`
- Training config:
  - Batch Size: 2
  - Epochs: 1
  - Optimizer: `adamw_8bit`
  - Sequence Length: 2048
  - LoRA rank: 16

---

## üß™ Evaluation

Custom evaluation script includes:
- Model inference using prompt chaining.
- Extraction of predicted `PointsMissed`.
- Automatic JSON-based comparison with ground truth.
- Metrics calculated:
  - ‚úÖ Precision
  - ‚úÖ Recall
  - ‚úÖ F1-score

---
## üìà Results

Our fine-tuned models were evaluated against GPT-4o, Gemini, and base models using precision, recall, and F1-score. Below is the performance comparison:

| Model                                      | Precision | Recall | F1-Score |
|-------------------------------------------|-----------|--------|----------|
| **Mistral-7B Instruct Finetuned**         | **0.7167** | 0.6767 | **0.6837** |
| Phi-3 Medium 4K Finetuned                 | 0.7194 | 0.6758 | 0.6830 |
| Qwen 2.5 7B Finetuned                     | 0.6586 | 0.6778 | 0.6526 |
| Gemma-2 9B Finetuned                      | 0.6173 | 0.6994 | 0.6388 |
| Qwen 2.5 14B Finetuned                    | 0.6692 | 0.6322 | 0.6381 |
| Mistral-Nemo Instruct Finetuned           | 0.6456 | 0.6311 | 0.6293 |
| **Gemini 2.0 - Flash**                    | 0.6766 | 0.6772 | 0.6631 |
| Gemini 1.5 - Flash                        | 0.6658 | 0.6833 | 0.6600 |
| ChatGPT-4o                                | 0.6560 | 0.6833 | 0.6536 |
| ChatGPT-4o Mini                           | 0.6512 | 0.6839 | 0.6517 |
| Phi-3 Medium 4K Base                      | 0.6153 | 0.5917 | 0.5925 |

> ‚úÖ **Best Performing Model**: `Mistral-7B Instruct Finetuned`  
> üìâ **Notably Outperformed**: `ChatGPT-4o`, `Gemini 2.0`, and all base models  
> üéØ Domain-specific fine-tuning showed consistent improvements in task performance.

### Visualization of Results

![Precision Comparison](https://github.com/astronova001/finetuning-small-llms-to-outperform-large-models-on-specific-tasks/blob/main/Results/f1_score_comparison.png)
*Precision scores across all evaluated models*

![Recall Comparison](Results/https://github.com/astronova001/finetuning-small-llms-to-outperform-large-models-on-specific-tasks/blob/main/Results/f1_score_comparison.png)
*Recall scores across all evaluated models*

![F1-Score Comparison](Results/https://github.com/astronova001/finetuning-small-llms-to-outperform-large-models-on-specific-tasks/blob/main/Results/model_performance_comparison.png)
*F1-score comparison showing our fine-tuned model outperforming GPT-4o and Gemini*

![Overall Performance](Results/https://github.com/astronova001/finetuning-small-llms-to-outperform-large-models-on-specific-tasks/blob/main/Results/metrics_heatmap.png)
*Comprehensive performance view of all metrics across evaluated models*

---

## üí¨ Key Takeaways

- Domain-specific fine-tuning can outperform even the most powerful foundation models on specific tasks.
- LoRA + Unsloth enables fast, memory-efficient training even on limited GPU resources like Kaggle T4.
- A clean evaluation pipeline is crucial for comparing models fairly.

---

## üì¶ Installation & Usage

```bash
# Install requirements
pip install unsloth

# Clone this repo and follow notebooks step by step
```

---

## üßë‚Äçüíª Author

**Vivek B S**  
Final Year CSE (AI & ML) | Passionate about LLMs & domain-specific AI  
[LinkedIn](https://www.linkedin.com/in/b-s-vivek/) | [GitHub](https://github.com/astronova001)

---
